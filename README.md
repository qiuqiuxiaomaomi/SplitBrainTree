# SplitBrainTree
脑裂技术研究


<pre>
ES集群脑裂
      ES集群出现了极端缓慢的情况。

      ElasticHeader，发现集群的总体状态是red,本来7个节点的集群，在结果中只显示了3个；
      正常情况下，集群中的所有的节点，应该对集群中master的选择是一致的，这样获得的状态信
   息也应该是一致的，不一致的状态说明不同的节点对master节点的选择出现了异常----脑裂问题。
   这样的脑裂状态直接让节点失去了集群的正确状态，导致集群不能正常工作。

   ES集群脑裂可能导致的原因
       1）网络问题：
       2）节点负载：
               由于master节点与data节点都是混合在一起的，所以当工作节点的负载较大时，导致
               对应的ES实例停止响应，而这台服务器如果正充当着master节点的身份，那么一部分
               节点就会认为这个master节点失效了，故重新选举新的节点，这时就出现脑裂问题；
               同时由于data节点上ES进程占用的内存较大，较大规模的内存回收操作也可能造成
               ES进程失去响应，所以，这个原因的可能性应该是最大的。
       3）回收内存：
               由于data节点上es进程占用的内存较大，较大规模的内存回收操作也能造成ES进程
               失去响应。

   ES集群脑裂问题的应对办法：
       1：节点负载导致了master进程停止响应，继而导致部分节点对于master的选择出现了分歧。
          为此，一个直观的解决方案是将master节点与data节点分离。master节点只是master节点
          。不但存储和搜索的角色，可以通过以下的配置来限制其角色。
              
              node.data:false
              node.master:true

          为了使新加入的节点快速确定master的位置，可以将data节点的默认的master发现方式
          由multicat修改为unicast

              discovery.zen.ping.multicast.enabled:false
              discovery.zen.pin.unicast.hosts:["master1", "master2", "master3"]

          还有两个直观的参数可以减缓脑裂问题的出现
              discovery.zen.ping_timeout:
                  默认值为3秒，默认情况下，一个节点会认为,如果master节点在3秒之内没有应答，
              那么这个节点就是down掉了，而增加这个值，会增加节点等待响应的时间，从而在一定程度
              上减少误判。
             
       2：彻底解决
          以上方法并不能彻底解决脑裂问题，只能减缓脑裂问题。
          当脑裂发生后，唯一的修复办法就是重启集群。这儿优点复杂和可怕。当ES集群启动时，会选出一个
          主节点（一般是启动的第一个节点被选为主）。由于索引的两份拷贝已经不一样了，ES会认为选出来
          的主保留的分片是“主拷贝”并将这份拷贝推送给集群中的其他节点。这很严重。如果一个节点保存了
          正确的数据，但是如果 另外一个节点先启动并被选为主，它会将一份过期的索引数据推送给另一个
          节点，覆盖它，导致丢失了有效数据。

       3：总结
          所以怎么从脑裂中回复？
              小心的重启你的集群。停掉所有的节点并决定哪一个节点第一个启动
           。如果需要，单独启动每一个节点并分析它保存的数据。如果不是有效的，关掉它，并删除它数据目
           录的内容（删除前先做个备份）。如果你找到了你想要保存的数据的节点，启动它并且检查日志确保
           它被选为主节点。这之后你可以安全的启动集群中的其他节点了。
</pre>